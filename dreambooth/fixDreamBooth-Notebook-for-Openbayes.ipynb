{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbdb2c9-4ce6-4ffd-92d7-6ebd91771f91",
   "metadata": {},
   "source": [
    "# Colab的默认环境跟这里的默认环境有差异，需要安装额外的依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9fae5b-6950-407b-bf57-be286109579b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T15:54:37.529524Z",
     "iopub.status.busy": "2022-12-12T15:54:37.529098Z",
     "iopub.status.idle": "2022-12-12T15:54:40.289042Z",
     "shell.execute_reply": "2022-12-12T15:54:40.288445Z",
     "shell.execute_reply.started": "2022-12-12T15:54:37.529484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 94 not upgraded.\n",
      "Need to get 2129 kB of archives.\n",
      "After this operation, 7662 kB of additional disk space will be used.\n",
      "Get:1 http://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2129 kB]\n",
      "Fetched 2129 kB in 0s (5726 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Selecting previously unselected package git-lfs.\n",
      "(Reading database ... 52279 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
      "Unpacking git-lfs (2.3.4-1) ...\n",
      "Setting up git-lfs (2.3.4-1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43a26af-ea59-43a1-b3a4-d7b24c366367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T16:25:07.379190Z",
     "iopub.status.busy": "2022-12-12T16:25:07.378811Z",
     "iopub.status.idle": "2022-12-12T16:25:22.500767Z",
     "shell.execute_reply": "2022-12-12T16:25:22.499494Z",
     "shell.execute_reply.started": "2022-12-12T16:25:07.379152Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.8/site-packages (3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/site-packages (4.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (1.26.11)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.8/site-packages (0.35.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting jax\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4b/0e/c57d1b4c9ddc27e8498c9e2b0628666c11d9d6911f1d2f975a91e1215595/jax-0.3.25.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/site-packages (from jax) (1.23.4)\n",
      "Collecting opt_einsum\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m38.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/site-packages (from jax) (1.9.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/site-packages (from jax) (4.4.0)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.3.25-py3-none-any.whl size=1308495 sha256=386cd1ae3be8471249cf179b2cb08193e7f22d3bf79b784ec3667c646b3439a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/b9/18/0f42bd0c697d360a5f3a4bdfd3fd88d0c9e1f1cfd86b5f8caf\n",
      "Successfully built jax\n",
      "Installing collected packages: opt_einsum, jax\n",
      "Successfully installed jax-0.3.25 opt_einsum-3.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Hit:1 http://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic InRelease\n",
      "Hit:2 https://deb.nodesource.com/node_14.x bionic InRelease                    \n",
      "Hit:3 http://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-backports InRelease    \n",
      "Hit:4 http://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-updates InRelease      \n",
      "Hit:5 http://mirrors.tuna.tsinghua.edu.cn/ubuntu bionic-security InRelease     \n",
      "Reading package lists... Done                                                  \n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "p7zip-full is already the newest version (16.02+dfsg-6).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 94 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!pip install transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install jax\n",
    "!apt-get update\n",
    "!apt-get install -y p7zip-full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d07e0b-3ecd-4873-a4a6-7466418da56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append('../') # 把上级路径也加入到系统路径中，这样就能够找到func\n",
    "from func.env import getOneClickDir\n",
    "\n",
    "oneClickDir=getOneClickDir()\n",
    "print(oneClickDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875e96c2-0706-4e04-813c-bf4a02a40017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T16:43:53.331938Z",
     "iopub.status.busy": "2022-12-12T16:43:53.331673Z",
     "iopub.status.idle": "2022-12-12T16:43:53.997204Z",
     "shell.execute_reply": "2022-12-12T16:43:53.996632Z",
     "shell.execute_reply.started": "2022-12-12T16:43:53.331918Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/OneClick-stable-diffusion/dreambooth/temp/fast-DreamBooth.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "# 在当前运行的ipynb文件所在的目录下创建临时文件夹temp\n",
    "def create_temp_folder(temp_folder):\n",
    "  if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)\n",
    "\n",
    "# 获取当前运行的 ipynb 文件所在的目录\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# 在该目录下创建临时文件夹 temp\n",
    "temp_folder = os.path.join(cwd, 'temp')\n",
    "\n",
    "# 如果temp文件夹不存在，则创建文件夹\n",
    "create_temp_folder(temp_folder)\n",
    "\n",
    "if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)\n",
    "\n",
    "# 覆盖下载 fast-DreamBooth.ipynb 文件到 temp 文件夹中\n",
    "file_name='fast-DreamBooth.ipynb'\n",
    "fastDreamBoothPath = os.path.join(temp_folder, file_name)\n",
    "if os.path.exists(fastDreamBoothPath):\n",
    "    os.remove(fastDreamBoothPath)\n",
    "fastDreamBoothPath = wget.download(\n",
    "    \"https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/fast-DreamBooth.ipynb\",\n",
    "    out=os.path.join(temp_folder, file_name)\n",
    ")\n",
    "print(fastDreamBoothPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbefc9-7c37-48bb-97e1-4fef802fc9af",
   "metadata": {},
   "source": [
    "# 清理Notebook中的输出，对Colab版中的路径进行替换，以适应openbayes的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73aec890-1745-4f77-b3bc-af98d1726554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T16:53:13.747901Z",
     "iopub.status.busy": "2022-12-12T16:53:13.747640Z",
     "iopub.status.idle": "2022-12-12T16:53:13.759090Z",
     "shell.execute_reply": "2022-12-12T16:53:13.758632Z",
     "shell.execute_reply.started": "2022-12-12T16:53:13.747877Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/OneClick-stable-diffusion/dreambooth/temp/fast-DreamBooth-modified.ipynb\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def modify_file_name(file_path):\n",
    "  # 获取文件名和文件扩展名\n",
    "  file_name, file_ext = os.path.splitext(file_path)\n",
    "  # 在文件名后加上 -modified\n",
    "  modified_file_path = file_name + \"-modified\" + file_ext\n",
    "  return modified_file_path\n",
    "\n",
    "def replace_root_path(notebook: str, old_root: str, new_root: str) -> str:\n",
    "    # 加载notebook\n",
    "    with open(notebook, \"r\") as f:\n",
    "        nb = json.load(f)\n",
    "\n",
    "    # 隐藏代码\n",
    "    for cell in nb[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            cell[\"metadata\"] = {\"collapsed\": True}\n",
    "\n",
    "    # 清空notebook中所有输出\n",
    "    for cell in nb['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            # 清除代码单元格的执行次数\n",
    "            cell['execution_count'] = None\n",
    "            # 清除代码单元格的输出\n",
    "            cell['outputs'] = []\n",
    "\n",
    "    # 替换旧的根路径为新的根路径\n",
    "    for cell in nb[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            for i, line in enumerate(cell[\"source\"]):\n",
    "                # 添加一个条件判断，只有当该行不是网址路径时才进行替换\n",
    "                if not line.startswith((\"http\", \"https\")):\n",
    "                    cell[\"source\"][i] = line.replace(old_root, new_root)\n",
    "                # 把引入google.colab的库的代码行标注为注释\n",
    "                if \"google.colab\" in line:\n",
    "                    cell[\"source\"][i] = \"# \" + line\n",
    "                # 把使用google drive盘挂载的代码行标注为注释\n",
    "                if \"drive.mount\" in line:\n",
    "                    cell[\"source\"][i] = \"# \" + line\n",
    "                \n",
    "                # # 原始字符串\n",
    "                # original = \"!cp -r /openbayes/home/content/usr/local/lib/python3.8/dist-packages /usr/local/lib/python3.8/\"\n",
    "                # if original in line:\n",
    "                #     # 替换python路径\n",
    "                #     cell[\"source\"][i] = re.sub(r'/usr/local/lib/python3.8/', '/usr/local/lib/python/', original)\n",
    "                    \n",
    "    # 替换@param{type: 'xxx'}中的单引号为双引号\n",
    "    for cell in nb[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            for i, line in enumerate(cell[\"source\"]):\n",
    "                if \"@param\" in line:\n",
    "                    cell[\"source\"][i] = line.replace(\"'\", '\"')\n",
    "                    \n",
    "    # 保存修改后的notebook\n",
    "    newNotebook=modify_file_name(notebook)\n",
    "    with open(newNotebook, \"w\") as f:\n",
    "        json.dump(nb, f)\n",
    "        \n",
    "    return newNotebook\n",
    "\n",
    "newNotebookPath=replace_root_path(\n",
    "    notebook=fastDreamBoothPath,\n",
    "    old_root=\"/content\",\n",
    "    new_root=\"/openbayes/home/content\"\n",
    ")\n",
    "print(newNotebookPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d9bdb-e926-428d-8ccf-38eacf11ed38",
   "metadata": {},
   "source": [
    "# 对指定的变量名进行字符串和参数的替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f98c0df-b75b-4bf3-ad0f-7181fd4f87f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T16:53:16.032081Z",
     "iopub.status.busy": "2022-12-12T16:53:16.031825Z",
     "iopub.status.idle": "2022-12-12T16:53:16.044002Z",
     "shell.execute_reply": "2022-12-12T16:53:16.043559Z",
     "shell.execute_reply.started": "2022-12-12T16:53:16.032060Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def keepAnnotationBehide(line):\n",
    "  identifier=\"#@param\"\n",
    "  if identifier in line:\n",
    "    annotation=line.split(identifier)[1]\n",
    "    return identifier+annotation\n",
    "\n",
    "def modify_file_name(file_path):\n",
    "  # 获取文件名和文件扩展名\n",
    "  file_name, file_ext = os.path.splitext(file_path)\n",
    "  # 在文件名后加上 -modified\n",
    "  modified_file_path = file_name + \"-customData\" + file_ext\n",
    "  return modified_file_path\n",
    "\n",
    "# 读取修改后的notebook\n",
    "def update_ipynb_vars(ipynb_file, var_map):\n",
    "  with open(ipynb_file, 'r') as f:\n",
    "    notebook = json.load(f)\n",
    "  \n",
    "  # 用更新后的值替换变量赋值\n",
    "  for cell in notebook['cells']:\n",
    "    if cell['cell_type'] == 'code':\n",
    "      for i in range(len(cell['source'])):\n",
    "        for var, val in var_map.items():\n",
    "          if isinstance(val, str):\n",
    "            val = f'\"{val}\"'\n",
    "          if cell['source'][i].startswith(f'{var} = '):\n",
    "            annotation=keepAnnotationBehide(cell['source'][i])\n",
    "            cell['source'][i] = f'{var} = {val} {annotation}\\n' \n",
    "\n",
    "\n",
    "  # 保存修改后的notebook\n",
    "  updatedDataNotebookPath=modify_file_name(ipynb_file)\n",
    "  with open(updatedDataNotebookPath, 'w') as f:\n",
    "    json.dump(notebook, f)\n",
    "\n",
    "  return updatedDataNotebookPath\n",
    "\n",
    "# 更新变量\n",
    "replacements = {\n",
    "  'Model_Version': 'V2.1-768px',\n",
    "  'Session_Name': 'FuXingHao768',\n",
    "  'Crop_size': 768,\n",
    "  'Remove_existing_instance_images': False,\n",
    "  'IMAGES_FOLDER_OPTIONAL':\"/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/FuXingHao768/instance_images\",\n",
    "  'Crop_images':False,\n",
    "  'Resolution': 768,\n",
    "}\n",
    "\n",
    "# 更新变量\n",
    "updatedDataNotebookPath=update_ipynb_vars(newNotebookPath, replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ba25c-f71f-479a-a8a8-76d11f81d5e8",
   "metadata": {},
   "source": [
    "# 检查最终版本的ipynb里面的赋值情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdea68b7-983a-4341-8fed-a2ac19e8fffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T16:44:00.431905Z",
     "iopub.status.busy": "2022-12-12T16:44:00.431656Z",
     "iopub.status.idle": "2022-12-12T16:44:00.438783Z",
     "shell.execute_reply": "2022-12-12T16:44:00.438152Z",
     "shell.execute_reply.started": "2022-12-12T16:44:00.431886Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Version: \"V2.1-768px\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
      "Huggingface_Token: \"\" #@param {type:\"string\"}\n",
      "token: Huggingface_Token\n",
      "Custom_Model_Version: \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
      "Path_to_HuggingFace: \"\" #@param {type:\"string\"}\n",
      "CKPT_Path: \"\" #@param {type:\"string\"}\n",
      "CKPT_Link: \"\" #@param {type:\"string\"}\n",
      "token: Huggingface_Token\n",
      "token: input(\"Insert your huggingface token :\")\n",
      "if Path_to_HuggingFace !: \"\":\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "elif CKPT_Path !: \"\":\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "elif CKPT_Link !: \"\":\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v1-5\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v1-5\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-512\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-512\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-768\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-768\"\n",
      "MODEL_NAME: \"\"\n",
      "PT: \"\"\n",
      "Session_Name: \"FuXingHao768\" #@param{type: \"string\"}\n",
      "Session_Name: input('')\n",
      "Session_Name: Session_Name.replace(\" \",\"_\")\n",
      "Session_Link_optional: \"\" #@param{type: \"string\"}\n",
      "WORKSPACE: '/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth'\n",
      "if Session_Link_optional !: \"\":\n",
      "if Session_Link_optional !: \"\":\n",
      "INSTANCE_NAME: Session_Name\n",
      "OUTPUT_DIR: \"/openbayes/home/content/models/\"+Session_Name\n",
      "SESSION_DIR: WORKSPACE+'/Sessions/'+Session_Name\n",
      "INSTANCE_DIR: SESSION_DIR+'/instance_images'\n",
      "CONCEPT_DIR: SESSION_DIR+'/concept_images'\n",
      "MDLPTH: str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
      "Model_Version: \"V2.1-768px\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
      "k: 0\n",
      "k: k+1\n",
      "k: 0\n",
      "k: k+1\n",
      "n: input()\n",
      "n: input()\n",
      "if n!: \"000\":\n",
      "resume: True\n",
      "Remove_existing_instance_images: True #@param{type: \"boolean\"}\n",
      "IMAGES_FOLDER_OPTIONAL: \"\" #@param{type: \"string\"}\n",
      "Crop_images: True #@param{type: \"boolean\"}\n",
      "Crop_size: 768 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
      "Crop_size: int(Crop_size)\n",
      "while IMAGES_FOLDER_OPTIONAL !: \"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
      "IMAGES_FOLDER_OPTIONAL: input('')\n",
      "if IMAGES_FOLDER_OPTIONAL!: \"\":\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[-1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(INSTANCE_DIR, filename)\n",
      "file: Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "uploaded: files.upload()\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[-1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(INSTANCE_DIR, filename)\n",
      "file: Image.open(new_path_with_file)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "Remove_existing_concept_images: True #@param{type: \"boolean\"}\n",
      "IMAGES_FOLDER_OPTIONAL: \"\" #@param{type: \"string\"}\n",
      "Crop_images: True\n",
      "Crop_size: 768 None\n",
      "Crop_size: int(Crop_size)\n",
      "while IMAGES_FOLDER_OPTIONAL !: \"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
      "IMAGES_FOLDER_OPTIONAL: input('')\n",
      "if IMAGES_FOLDER_OPTIONAL!: \"\":\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[-1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(CONCEPT_DIR, filename)\n",
      "file: Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "uploaded: files.upload()\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[-1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(CONCEPT_DIR, filename)\n",
      "file: Image.open(new_path_with_file)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "i: 0\n",
      "extension: filename.split(\".\")[-1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(CONCEPT_DIR, \"conceptimagedb\"+str(i)+\".\"+extension)\n",
      "filepath: os.path.join(CONCEPT_DIR,filename)\n",
      "i: i+1\n",
      "Resume_Training: False #@param {type:\"boolean\"}\n",
      "ansres: input('')\n",
      "Resume_Training: True\n",
      "Resume_Training: False\n",
      "resume: False\n",
      "MODELT_NAME: MODEL_NAME\n",
      "UNet_Training_Steps: 3000 #@param{type: \"number\"}\n",
      "Text_Encoder_Training_Steps: 350 #@param{type: \"number\"}\n",
      "Text_Encoder_Concept_Training_Steps: 0 #@param{type: \"number\"}\n",
      "trnonltxt: \"\"\n",
      "trnonltxt: \"--train_only_text_encoder\"\n",
      "Seed: ''\n",
      "Style_Training: False #@param {type:\"boolean\"}\n",
      "Style: \"\"\n",
      "Style: \"--Style\"\n",
      "Resolution: 768 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
      "Res: int(Resolution)\n",
      "#@markdown - Higher resolution: Higher quality, make sure the instance images are cropped to this selected size (or larger).\n",
      "fp16: True\n",
      "Seed: random.randint(1, 999999)\n",
      "Seed: int(Seed)\n",
      "prec: \"fp16\"\n",
      "prec: \"no\"\n",
      "s: getoutput('nvidia-smi')\n",
      "precision: \"no\"\n",
      "precision: prec\n",
      "resuming: \"\"\n",
      "MODELT_NAME: OUTPUT_DIR\n",
      "resuming: \"Yes\"\n",
      "MODELT_NAME: MODEL_NAME\n",
      "V2: False\n",
      "V2: True\n",
      "Enable_text_encoder_training: True\n",
      "Enable_Text_Encoder_Concept_Training: True\n",
      "Enable_text_encoder_training: False\n",
      "stptxt: Text_Encoder_Training_Steps\n",
      "Enable_Text_Encoder_Concept_Training: False\n",
      "stptxtc: Text_Encoder_Concept_Training_Steps\n",
      "Textenc: \"--train_text_encoder\"\n",
      "Textenc: \"\"\n",
      "Save_Checkpoint_Every_n_Steps: False #@param {type:\"boolean\"}\n",
      "Save_Checkpoint_Every: 500 #@param{type: \"number\"}\n",
      "Save_Checkpoint_Every: 1\n",
      "stp: 0\n",
      "Start_saving_from_the_step: 500 #@param{type: \"number\"}\n",
      "Start_saving_from_the_step: 0\n",
      "Start_saving_from_the_step: Save_Checkpoint_Every\n",
      "stpsv: Start_saving_from_the_step\n",
      "stp: Save_Checkpoint_Every\n",
      "Disconnect_after_training: False #@param {type:\"boolean\"}\n",
      "--pretrained_model_name_or_path: \"$MODELT_NAME\" \\\n",
      "--instance_data_dir: \"$INSTANCE_DIR\" \\\n",
      "--output_dir: \"$OUTPUT_DIR\" \\\n",
      "--instance_prompt: \"$PT\" \\\n",
      "--seed: $Seed \\\n",
      "--resolution: 512 \\\n",
      "--mixed_precision: $precision \\\n",
      "--train_batch_size: 1 \\\n",
      "--gradient_accumulation_steps: 1 --gradient_checkpointing \\\n",
      "--learning_rate: 2e-6 \\\n",
      "--lr_scheduler: \"polynomial\" \\\n",
      "--lr_warmup_steps: 0 \\\n",
      "--max_train_steps: $Training_Steps\n",
      "--save_starting_step: $stpsv \\\n",
      "--save_n_steps: $stp \\\n",
      "--Session_dir: $SESSION_DIR \\\n",
      "--pretrained_model_name_or_path: \"$MODELT_NAME\" \\\n",
      "--instance_data_dir: \"$INSTANCE_DIR\" \\\n",
      "--output_dir: \"$OUTPUT_DIR\" \\\n",
      "--instance_prompt: \"$PT\" \\\n",
      "--seed: $Seed \\\n",
      "--resolution: $Res \\\n",
      "--mixed_precision: $precision \\\n",
      "--train_batch_size: 1 \\\n",
      "--gradient_accumulation_steps: 1 --gradient_checkpointing \\\n",
      "--learning_rate: 2e-6 \\\n",
      "--lr_scheduler: \"polynomial\" \\\n",
      "--lr_warmup_steps: 0 \\\n",
      "--max_train_steps: $Training_Steps\n",
      "dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps: stptxt)\n",
      "if Enable_Text_Encoder_Concept_Training and os.listdir(CONCEPT_DIR)!: []:\n",
      "dump_only_textenc(trnonltxt, MODELT_NAME, CONCEPT_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps: stptxtc)\n",
      "if UNet_Training_Steps!: 0:\n",
      "train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps: UNet_Training_Steps)\n",
      "!sed -i '201s@.*@    model_path: \"{OUTPUT_DIR}\"@' /openbayes/home/content/convertosd.py\n",
      "!sed -i '202s@.*@    checkpoint_path: \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /openbayes/home/content/convertosd.py\n",
      "Model_Version: \"V2.1-768px\" #@param [\"1.5\", \"V2.1-512\", \"V2.1-768\"]\n",
      "Update_repo: True #@param {type:\"boolean\"}\n",
      "Session__Name: \"\" #@param{type: \"string\"}\n",
      "Use_Custom_Path: False #@param {type:\"boolean\"}\n",
      "INSTANCET: INSTANCE_NAME\n",
      "if Session__Name!: \"\":\n",
      "INSTANCET: Session__Name\n",
      "INSTANCET: INSTANCET.replace(\" \",\"_\")\n",
      "if Session__Name!: \"\":\n",
      "path_to_trained_model: '/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/'+Session__Name+\"/\"+Session__Name+'.ckpt'\n",
      "path_to_trained_model: SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
      "path_to_trained_model: input()\n",
      "path_to_trained_model: input()\n",
      "!sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count: 10)@' /openbayes/home/content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
      "Use_Gradio_Server: False #@param {type:\"boolean\"}\n",
      "share: ''\n",
      "share: '--share'\n",
      "for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace: True):\n",
      "if line.strip().startswith('self.server_name: '):\n",
      "if line.strip().startswith('self.server_port: '):\n",
      "share: ''\n",
      "srv: getoutput('cat /openbayes/home/content/srvr.txt')\n",
      "for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace: True):\n",
      "if line.strip().startswith('self.server_name: '):\n",
      "if line.strip().startswith('self.server_port: '):\n",
      "if line.strip().startswith('self.protocol: \"https\"'):\n",
      "line: ''\n",
      "line: ''\n",
      "configf: \"--config /openbayes/home/content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference-v.yaml\"\n",
      "!sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location: \"cuda\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py\n",
      "NM: \"True\"\n",
      "configf: \"--config /openbayes/home/content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference.yaml\"\n",
      "!sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location: \"cuda\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py\n",
      "NM: \"True\"\n",
      "configf: \"\"\n",
      "!sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location: \"cpu\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py\n",
      "NM: \"False\"\n",
      "xformers: \"--xformers\"\n",
      "xformers: \"\"\n",
      "Upload_sample_images: False #@param {type:\"boolean\"}\n",
      "Name_of_your_concept: \"\" #@param {type:\"string\"}\n",
      "Name_of_your_concept: Session_Name\n",
      "Name_of_your_concept: Name_of_your_concept.replace(\" \",\"-\")\n",
      "Save_concept_to: \"My_Profile\" #@param [\"Public_Library\", \"My_Profile\"]\n",
      "hf_token_write: \"\" #@param {type:\"string\"}\n",
      "hf_token_write: input()\n",
      "hf_token: hf_token_write\n",
      "api: HfApi()\n",
      "repo_id: f\"sd-dreambooth-library/{slugify(Name_of_your_concept)}\"\n",
      "repo_id: f\"{your_username}/{slugify(Name_of_your_concept)}\"\n",
      "output_dir: f'/openbayes/home/content/models/'+INSTANCE_NAME\n",
      "br: \"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
      "image_string: \"\"\n",
      "Samples: \"/openbayes/home/content/sample_images\"\n",
      "uploaded: files.upload()\n",
      "images_upload: os.listdir(Samples)\n",
      "instance_prompt_list: []\n",
      "image_string: f'''\n",
      "readme_text: f'''---\n",
      "### {Name_of_your_concept} Dreambooth model trained by {api.whoami(token: hf_token)[\"name\"]} with [TheLastBen's fast-DreamBooth](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) notebook\n",
      "readme_file: open(\"README.md\", \"w\")\n",
      "operations: [\n",
      "repo_id: repo_id,\n",
      "operations: operations,\n",
      "commit_message: f\"Upload the concept {Name_of_your_concept} embeds and token\",\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/feature_extractor\",\n",
      "path_in_repo: \"feature_extractor\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/safety_checker\",\n",
      "path_in_repo: \"safety_checker\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/scheduler\",\n",
      "path_in_repo: \"scheduler\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/text_encoder\",\n",
      "path_in_repo: \"text_encoder\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/tokenizer\",\n",
      "path_in_repo: \"tokenizer\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/unet\",\n",
      "path_in_repo: \"unet\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/vae\",\n",
      "path_in_repo: \"vae\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "path_or_fileobj: OUTPUT_DIR+\"/model_index.json\",\n",
      "path_in_repo: \"model_index.json\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: Samples,\n",
      "path_in_repo: \"sample_images\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "''', raw: True)\n",
      "Sessions: os.listdir(\"/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
      "s: widgets.Select(\n",
      "options: Sessions,\n",
      "rows: 5,\n",
      "description: '',\n",
      "disabled: False\n",
      "out: widgets.Output()\n",
      "d: widgets.Button(\n",
      "description: 'Remove',\n",
      "disabled: False,\n",
      "button_style: 'warning',\n",
      "tooltip: 'Removet the selected session',\n",
      "icon: 'warning'\n",
      "s.options: os.listdir(\"/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def detect_constant_assignments(ipynb_file: str):\n",
    "    with open(ipynb_file, 'r') as f:\n",
    "        ipynb_data = json.load(f)\n",
    "\n",
    "    # 遍历所有的代码单元\n",
    "    for cell in ipynb_data['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            # 遍历当前代码单元中的所有行\n",
    "            for line in cell['source']:\n",
    "                # 检测是否是赋值行，并获取变量名和值\n",
    "                parts = line.split('=')\n",
    "                if len(parts) == 2:\n",
    "                    var_name = parts[0].strip()\n",
    "                    value = parts[1].strip()\n",
    "                    print(f'{var_name}: {value}')\n",
    "\n",
    "detect_constant_assignments(updatedDataNotebookPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ad5bc-4cea-453b-930a-054f0eb2d6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
