{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43a26af-ea59-43a1-b3a4-d7b24c366367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T10:08:38.107735Z",
     "iopub.status.busy": "2022-12-12T10:08:38.107439Z",
     "iopub.status.idle": "2022-12-12T10:08:39.706172Z",
     "shell.execute_reply": "2022-12-12T10:08:39.705726Z",
     "shell.execute_reply.started": "2022-12-12T10:08:38.107695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.8/site-packages (3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d07e0b-3ecd-4873-a4a6-7466418da56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append('../') # 把上级路径也加入到系统路径中，这样就能够找到func\n",
    "from func.env import getOneClickDir\n",
    "\n",
    "oneClickDir=getOneClickDir()\n",
    "print(oneClickDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875e96c2-0706-4e04-813c-bf4a02a40017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T10:41:31.640832Z",
     "iopub.status.busy": "2022-12-12T10:41:31.640493Z",
     "iopub.status.idle": "2022-12-12T10:41:31.912026Z",
     "shell.execute_reply": "2022-12-12T10:41:31.911596Z",
     "shell.execute_reply.started": "2022-12-12T10:41:31.640811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/OneClick-stable-diffusion/dreambooth/temp/fast-DreamBooth.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "# 在当前运行的ipynb文件所在的目录下创建临时文件夹temp\n",
    "def create_temp_folder(temp_folder):\n",
    "  if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)\n",
    "\n",
    "# 获取当前运行的 ipynb 文件所在的目录\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# 在该目录下创建临时文件夹 temp\n",
    "temp_folder = os.path.join(cwd, 'temp')\n",
    "\n",
    "# 如果temp文件夹不存在，则创建文件夹\n",
    "create_temp_folder(temp_folder)\n",
    "\n",
    "if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)\n",
    "\n",
    "# 覆盖下载 fast-DreamBooth.ipynb 文件到 temp 文件夹中\n",
    "fastDreamBoothPath = os.path.join(temp_folder, 'fast-DreamBooth.ipynb')\n",
    "if os.path.exists(fastDreamBoothPath):\n",
    "    os.remove(fastDreamBoothPath)\n",
    "fastDreamBoothPath = wget.download(\n",
    "    \"https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/fast-DreamBooth.ipynb\",\n",
    "    out=os.path.join(temp_folder, file_name)\n",
    ")\n",
    "print(fastDreamBoothPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73aec890-1745-4f77-b3bc-af98d1726554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T12:35:30.005881Z",
     "iopub.status.busy": "2022-12-12T12:35:30.005489Z",
     "iopub.status.idle": "2022-12-12T12:35:30.014815Z",
     "shell.execute_reply": "2022-12-12T12:35:30.014342Z",
     "shell.execute_reply.started": "2022-12-12T12:35:30.005854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/OneClick-stable-diffusion/dreambooth/temp/fast-DreamBooth-modified.ipynb\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def modify_file_name(file_path):\n",
    "  # 获取文件名和文件扩展名\n",
    "  file_name, file_ext = os.path.splitext(file_path)\n",
    "  # 在文件名后加上 -modified\n",
    "  modified_file_path = file_name + \"-modified\" + file_ext\n",
    "  return modified_file_path\n",
    "\n",
    "def replace_root_path(notebook: str, old_root: str, new_root: str) -> str:\n",
    "    # 加载notebook\n",
    "    with open(notebook, \"r\") as f:\n",
    "        nb = json.load(f)\n",
    "\n",
    "    # 隐藏代码\n",
    "    for cell in nb[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            cell[\"metadata\"] = {\"collapsed\": True}\n",
    "\n",
    "    # 清空notebook中所有输出\n",
    "    for cell in nb['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            # 清除代码单元格的执行次数\n",
    "            cell['execution_count'] = None\n",
    "            # 清除代码单元格的输出\n",
    "            cell['outputs'] = []\n",
    "\n",
    "    # 替换旧的根路径为新的根路径\n",
    "    for cell in nb[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            for i, line in enumerate(cell[\"source\"]):\n",
    "                # 添加一个条件判断，只有当该行不是网址路径时才进行替换\n",
    "                if not line.startswith((\"http\", \"https\")):\n",
    "                    cell[\"source\"][i] = line.replace(old_root, new_root)\n",
    "\n",
    "    # 替换@param{type: 'xxx'}中的单引号为双引号\n",
    "    for cell in nb[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            for i, line in enumerate(cell[\"source\"]):\n",
    "                if \"@param\" in line:\n",
    "                    cell[\"source\"][i] = line.replace(\"'\", '\"')\n",
    "                    \n",
    "    # 保存修改后的notebook\n",
    "    newNotebook=modify_file_name(notebook)\n",
    "    with open(newNotebook, \"w\") as f:\n",
    "        json.dump(nb, f)\n",
    "        \n",
    "    return newNotebook\n",
    "\n",
    "newNotebookPath=replace_root_path(\n",
    "    notebook=fastDreamBoothPath,\n",
    "    old_root=\"/content\",\n",
    "    new_root=\"/openbayes/home/content\"\n",
    ")\n",
    "print(newNotebookPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f98c0df-b75b-4bf3-ad0f-7181fd4f87f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T12:47:34.137869Z",
     "iopub.status.busy": "2022-12-12T12:47:34.137577Z",
     "iopub.status.idle": "2022-12-12T12:47:34.145076Z",
     "shell.execute_reply": "2022-12-12T12:47:34.144668Z",
     "shell.execute_reply.started": "2022-12-12T12:47:34.137851Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_ipynb_vars(ipynb_file, var_map):\n",
    "  with open(ipynb_file, 'r') as f:\n",
    "    notebook = json.load(f)\n",
    "  \n",
    "  # Replace variable assignments with updated values\n",
    "  for cell in notebook['cells']:\n",
    "    if cell['cell_type'] == 'code':\n",
    "      for i in range(len(cell['source'])):\n",
    "        for var, val in var_map.items():\n",
    "          if isinstance(val, str):\n",
    "            val = f'\"{val}\"'\n",
    "          if cell['source'][i].startswith(f'{var} = '):\n",
    "            cell['source'][i] = f'{var} = {val}\\n'\n",
    "\n",
    "  # Write updated notebook to file\n",
    "  with open(ipynb_file, 'w') as f:\n",
    "    json.dump(notebook, f)\n",
    "\n",
    "\n",
    "replacements = {\n",
    "  'Model_Version': 'V2.1-768px',\n",
    "  'Session_Name': 'FuXingHao768',\n",
    "  'Crop_size': 768\n",
    "}\n",
    "\n",
    "update_ipynb_vars(newNotebookPath, replacements)\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdea68b7-983a-4341-8fed-a2ac19e8fffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T12:10:54.597108Z",
     "iopub.status.busy": "2022-12-12T12:10:54.596665Z",
     "iopub.status.idle": "2022-12-12T12:10:54.604254Z",
     "shell.execute_reply": "2022-12-12T12:10:54.603821Z",
     "shell.execute_reply.started": "2022-12-12T12:10:54.597086Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Version: \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
      "Huggingface_Token: \"\" #@param {type:\"string\"}\n",
      "token: Huggingface_Token\n",
      "Custom_Model_Version: \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
      "Path_to_HuggingFace: \"\" #@param {type:\"string\"}\n",
      "CKPT_Path: \"\" #@param {type:\"string\"}\n",
      "CKPT_Link: \"\" #@param {type:\"string\"}\n",
      "token: Huggingface_Token\n",
      "token: input(\"Insert your huggingface token :\")\n",
      "if Path_to_HuggingFace !: \"\":\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "elif CKPT_Path !: \"\":\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "elif CKPT_Link !: \"\":\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-custom\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v1-5\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v1-5\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-512\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-512\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-768\"\n",
      "MODEL_NAME: \"/openbayes/home/content/stable-diffusion-v2-768\"\n",
      "MODEL_NAME: \"\"\n",
      "PT: \"\"\n",
      "Session_Name: \"\" #@param{type: \"string\"}\n",
      "Session_Name: input('')\n",
      "Session_Name: Session_Name.replace(\" \",\"_\")\n",
      "Session_Link_optional: \"\" #@param{type: \"string\"}\n",
      "WORKSPACE: '/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth'\n",
      "if Session_Link_optional !: \"\":\n",
      "if Session_Link_optional !: \"\":\n",
      "INSTANCE_NAME: Session_Name\n",
      "OUTPUT_DIR: \"/openbayes/home/content/models/\"+Session_Name\n",
      "SESSION_DIR: WORKSPACE+'/Sessions/'+Session_Name\n",
      "INSTANCE_DIR: SESSION_DIR+'/instance_images'\n",
      "CONCEPT_DIR: SESSION_DIR+'/concept_images'\n",
      "MDLPTH: str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
      "Model_Version: \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
      "k: 0\n",
      "k: k+1\n",
      "k: 0\n",
      "k: k+1\n",
      "n: input()\n",
      "n: input()\n",
      "if n!: \"000\":\n",
      "resume: True\n",
      "Remove_existing_instance_images: True #@param{type: \"boolean\"}\n",
      "IMAGES_FOLDER_OPTIONAL: \"\" #@param{type: \"string\"}\n",
      "Crop_images: True #@param{type: \"boolean\"}\n",
      "Crop_size: \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
      "Crop_size: int(Crop_size)\n",
      "while IMAGES_FOLDER_OPTIONAL !: \"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
      "IMAGES_FOLDER_OPTIONAL: input('')\n",
      "if IMAGES_FOLDER_OPTIONAL!: \"\":\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(INSTANCE_DIR, filename)\n",
      "file: Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "uploaded: files.upload()\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(INSTANCE_DIR, filename)\n",
      "file: Image.open(new_path_with_file)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "Remove_existing_concept_images: True #@param{type: \"boolean\"}\n",
      "IMAGES_FOLDER_OPTIONAL: \"\" #@param{type: \"string\"}\n",
      "Crop_images: True\n",
      "Crop_size: \"512\"\n",
      "Crop_size: int(Crop_size)\n",
      "while IMAGES_FOLDER_OPTIONAL !: \"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
      "IMAGES_FOLDER_OPTIONAL: input('')\n",
      "if IMAGES_FOLDER_OPTIONAL!: \"\":\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(CONCEPT_DIR, filename)\n",
      "file: Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "uploaded: files.upload()\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "extension: filename.split(\".\")[1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(CONCEPT_DIR, filename)\n",
      "file: Image.open(new_path_with_file)\n",
      "width, height: file.size\n",
      "if file.size !: (Crop_size, Crop_size):\n",
      "side_length: min(width, height)\n",
      "left: (width - side_length)/2\n",
      "top: (height - side_length)/2\n",
      "right: (width + side_length)/2\n",
      "bottom: (height + side_length)/2\n",
      "image: file.crop((left, top, right, bottom))\n",
      "image: image.resize((Crop_size, Crop_size))\n",
      "image.save(new_path_with_file, format: extension.upper())\n",
      "for filename in tqdm(uploaded.keys(), bar_format: '  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
      "i: 0\n",
      "extension: filename.split(\".\")[1]\n",
      "identifier: filename.split(\".\")[0]\n",
      "new_path_with_file: os.path.join(CONCEPT_DIR, \"conceptimagedb\"+str(i)+\".\"+extension)\n",
      "filepath: os.path.join(CONCEPT_DIR,filename)\n",
      "i: i+1\n",
      "Resume_Training: False #@param {type:\"boolean\"}\n",
      "ansres: input('')\n",
      "Resume_Training: True\n",
      "Resume_Training: False\n",
      "resume: False\n",
      "MODELT_NAME: MODEL_NAME\n",
      "UNet_Training_Steps: 3000 #@param{type: \"number\"}\n",
      "Text_Encoder_Training_Steps: 350 #@param{type: \"number\"}\n",
      "Text_Encoder_Concept_Training_Steps: 0 #@param{type: \"number\"}\n",
      "trnonltxt: \"\"\n",
      "trnonltxt: \"--train_only_text_encoder\"\n",
      "Seed: ''\n",
      "Style_Training: False #@param {type:\"boolean\"}\n",
      "Style: \"\"\n",
      "Style: \"--Style\"\n",
      "Resolution: \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
      "Res: int(Resolution)\n",
      "#@markdown - Higher resolution: Higher quality, make sure the instance images are cropped to this selected size (or larger).\n",
      "fp16: True\n",
      "Seed: random.randint(1, 999999)\n",
      "Seed: int(Seed)\n",
      "prec: \"fp16\"\n",
      "prec: \"no\"\n",
      "s: getoutput('nvidia-smi')\n",
      "precision: \"no\"\n",
      "precision: prec\n",
      "resuming: \"\"\n",
      "MODELT_NAME: OUTPUT_DIR\n",
      "resuming: \"Yes\"\n",
      "MODELT_NAME: MODEL_NAME\n",
      "V2: False\n",
      "V2: True\n",
      "Enable_text_encoder_training: True\n",
      "Enable_Text_Encoder_Concept_Training: True\n",
      "Enable_text_encoder_training: False\n",
      "stptxt: Text_Encoder_Training_Steps\n",
      "Enable_Text_Encoder_Concept_Training: False\n",
      "stptxtc: Text_Encoder_Concept_Training_Steps\n",
      "Textenc: \"--train_text_encoder\"\n",
      "Textenc: \"\"\n",
      "Save_Checkpoint_Every_n_Steps: False #@param {type:\"boolean\"}\n",
      "Save_Checkpoint_Every: 500 #@param{type: \"number\"}\n",
      "Save_Checkpoint_Every: 1\n",
      "stp: 0\n",
      "Start_saving_from_the_step: 500 #@param{type: \"number\"}\n",
      "Start_saving_from_the_step: 0\n",
      "Start_saving_from_the_step: Save_Checkpoint_Every\n",
      "stpsv: Start_saving_from_the_step\n",
      "stp: Save_Checkpoint_Every\n",
      "Disconnect_after_training: False #@param {type:\"boolean\"}\n",
      "--pretrained_model_name_or_path: \"$MODELT_NAME\" \\\n",
      "--instance_data_dir: \"$INSTANCE_DIR\" \\\n",
      "--output_dir: \"$OUTPUT_DIR\" \\\n",
      "--instance_prompt: \"$PT\" \\\n",
      "--seed: $Seed \\\n",
      "--resolution: 512 \\\n",
      "--mixed_precision: $precision \\\n",
      "--train_batch_size: 1 \\\n",
      "--gradient_accumulation_steps: 1 --gradient_checkpointing \\\n",
      "--learning_rate: 2e-6 \\\n",
      "--lr_scheduler: \"polynomial\" \\\n",
      "--lr_warmup_steps: 0 \\\n",
      "--max_train_steps: $Training_Steps\n",
      "--save_starting_step: $stpsv \\\n",
      "--save_n_steps: $stp \\\n",
      "--Session_dir: $SESSION_DIR \\\n",
      "--pretrained_model_name_or_path: \"$MODELT_NAME\" \\\n",
      "--instance_data_dir: \"$INSTANCE_DIR\" \\\n",
      "--output_dir: \"$OUTPUT_DIR\" \\\n",
      "--instance_prompt: \"$PT\" \\\n",
      "--seed: $Seed \\\n",
      "--resolution: $Res \\\n",
      "--mixed_precision: $precision \\\n",
      "--train_batch_size: 1 \\\n",
      "--gradient_accumulation_steps: 1 --gradient_checkpointing \\\n",
      "--learning_rate: 2e-6 \\\n",
      "--lr_scheduler: \"polynomial\" \\\n",
      "--lr_warmup_steps: 0 \\\n",
      "--max_train_steps: $Training_Steps\n",
      "dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps: stptxt)\n",
      "if Enable_Text_Encoder_Concept_Training and os.listdir(CONCEPT_DIR)!: []:\n",
      "dump_only_textenc(trnonltxt, MODELT_NAME, CONCEPT_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps: stptxtc)\n",
      "if UNet_Training_Steps!: 0:\n",
      "train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps: UNet_Training_Steps)\n",
      "!sed -i '201s@.*@    model_path: \"{OUTPUT_DIR}\"@' /openbayes/home/content/convertosd.py\n",
      "!sed -i '202s@.*@    checkpoint_path: \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /openbayes/home/content/convertosd.py\n",
      "Model_Version: \"1.5\" #@param [\"1.5\", \"V2.1-512\", \"V2.1-768\"]\n",
      "Update_repo: True #@param {type:\"boolean\"}\n",
      "Session__Name: \"\" #@param{type: \"string\"}\n",
      "Use_Custom_Path: False #@param {type:\"boolean\"}\n",
      "INSTANCET: INSTANCE_NAME\n",
      "if Session__Name!: \"\":\n",
      "INSTANCET: Session__Name\n",
      "INSTANCET: INSTANCET.replace(\" \",\"_\")\n",
      "if Session__Name!: \"\":\n",
      "path_to_trained_model: '/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/'+Session__Name+\"/\"+Session__Name+'.ckpt'\n",
      "path_to_trained_model: SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
      "path_to_trained_model: input()\n",
      "path_to_trained_model: input()\n",
      "!sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count: 10)@' /openbayes/home/content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
      "Use_Gradio_Server: False #@param {type:\"boolean\"}\n",
      "share: ''\n",
      "share: '--share'\n",
      "for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace: True):\n",
      "if line.strip().startswith('self.server_name: '):\n",
      "if line.strip().startswith('self.server_port: '):\n",
      "share: ''\n",
      "srv: getoutput('cat /openbayes/home/content/srvr.txt')\n",
      "for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace: True):\n",
      "if line.strip().startswith('self.server_name: '):\n",
      "if line.strip().startswith('self.server_port: '):\n",
      "if line.strip().startswith('self.protocol: \"https\"'):\n",
      "line: ''\n",
      "line: ''\n",
      "configf: \"--config /openbayes/home/content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference-v.yaml\"\n",
      "!sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location: \"cuda\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py\n",
      "NM: \"True\"\n",
      "configf: \"--config /openbayes/home/content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference.yaml\"\n",
      "!sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location: \"cuda\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py\n",
      "NM: \"True\"\n",
      "configf: \"\"\n",
      "!sed -i 's@def load_state_dict(checkpoint_path: str, map_location.*@def load_state_dict(checkpoint_path: str, map_location: \"cpu\"):@' /usr/local/lib/python3.8/dist-packages/open_clip/factory.py\n",
      "NM: \"False\"\n",
      "xformers: \"--xformers\"\n",
      "xformers: \"\"\n",
      "Upload_sample_images: False #@param {type:\"boolean\"}\n",
      "Name_of_your_concept: \"\" #@param {type:\"string\"}\n",
      "Name_of_your_concept: Session_Name\n",
      "Name_of_your_concept: Name_of_your_concept.replace(\" \",\"-\")\n",
      "Save_concept_to: \"My_Profile\" #@param [\"Public_Library\", \"My_Profile\"]\n",
      "hf_token_write: \"\" #@param {type:\"string\"}\n",
      "hf_token_write: input()\n",
      "hf_token: hf_token_write\n",
      "api: HfApi()\n",
      "repo_id: f\"sd-dreambooth-library/{slugify(Name_of_your_concept)}\"\n",
      "repo_id: f\"{your_username}/{slugify(Name_of_your_concept)}\"\n",
      "output_dir: f'/openbayes/home/content/models/'+INSTANCE_NAME\n",
      "br: \"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
      "image_string: \"\"\n",
      "Samples: \"/openbayes/home/content/sample_images\"\n",
      "uploaded: files.upload()\n",
      "images_upload: os.listdir(Samples)\n",
      "instance_prompt_list: []\n",
      "image_string: f'''\n",
      "readme_text: f'''---\n",
      "### {Name_of_your_concept} Dreambooth model trained by {api.whoami(token: hf_token)[\"name\"]} with [TheLastBen's fast-DreamBooth](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) notebook\n",
      "readme_file: open(\"README.md\", \"w\")\n",
      "operations: [\n",
      "repo_id: repo_id,\n",
      "operations: operations,\n",
      "commit_message: f\"Upload the concept {Name_of_your_concept} embeds and token\",\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/feature_extractor\",\n",
      "path_in_repo: \"feature_extractor\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/safety_checker\",\n",
      "path_in_repo: \"safety_checker\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/scheduler\",\n",
      "path_in_repo: \"scheduler\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/text_encoder\",\n",
      "path_in_repo: \"text_encoder\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/tokenizer\",\n",
      "path_in_repo: \"tokenizer\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/unet\",\n",
      "path_in_repo: \"unet\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: OUTPUT_DIR+\"/vae\",\n",
      "path_in_repo: \"vae\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "path_or_fileobj: OUTPUT_DIR+\"/model_index.json\",\n",
      "path_in_repo: \"model_index.json\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "folder_path: Samples,\n",
      "path_in_repo: \"sample_images\",\n",
      "repo_id: repo_id,\n",
      "token: hf_token\n",
      "''', raw: True)\n",
      "Sessions: os.listdir(\"/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n",
      "s: widgets.Select(\n",
      "options: Sessions,\n",
      "rows: 5,\n",
      "description: '',\n",
      "disabled: False\n",
      "out: widgets.Output()\n",
      "d: widgets.Button(\n",
      "description: 'Remove',\n",
      "disabled: False,\n",
      "button_style: 'warning',\n",
      "tooltip: 'Removet the selected session',\n",
      "icon: 'warning'\n",
      "s.options: os.listdir(\"/openbayes/home/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def detect_constant_assignments(ipynb_file: str):\n",
    "    with open(ipynb_file, 'r') as f:\n",
    "        ipynb_data = json.load(f)\n",
    "\n",
    "    # 遍历所有的代码单元\n",
    "    for cell in ipynb_data['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            # 遍历当前代码单元中的所有行\n",
    "            for line in cell['source']:\n",
    "                # 检测是否是赋值行，并获取变量名和值\n",
    "                parts = line.split('=')\n",
    "                if len(parts) == 2:\n",
    "                    var_name = parts[0].strip()\n",
    "                    value = parts[1].strip()\n",
    "                    print(f'{var_name}: {value}')\n",
    "\n",
    "detect_constant_assignments(newNotebookPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ad5bc-4cea-453b-930a-054f0eb2d6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
